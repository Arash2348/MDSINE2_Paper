{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/gerberlab/MDSINE2_Paper/blob/master/google_colab/tutorial3_reproduce_figures.ipynb)\n",
        "# Figures for MDSINE2\n",
        "\n",
        "The codes below reproduce the figures appearing in the paper, \"***Intrinsic instability of the dysbiotic microbiome revealed through dynamical systems inference at scale ***\". The output figures are saved in `MDSINE2_Paper/analysis/gibson_inference/figures/output_figures/`. \n"
      ],
      "metadata": {
        "id": "1mNPGOyE4CsO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Dependency Initializations"
      ],
      "metadata": {
        "id": "WcSOQXvePxlX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Install Necessary libraries"
      ],
      "metadata": {
        "id": "3ocldvNHP9UQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/gerberlab/MDSINE2\n",
        "!pip install MDSINE2/.\n"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'MDSINE2'...\n",
            "remote: Enumerating objects: 3021, done.\u001b[K\n",
            "remote: Counting objects: 100% (930/930), done.\u001b[K\n",
            "remote: Compressing objects: 100% (650/650), done.\u001b[K\n",
            "remote: Total 3021 (delta 623), reused 531 (delta 271), pack-reused 2091\u001b[K\n",
            "Receiving objects: 100% (3021/3021), 78.20 MiB | 9.60 MiB/s, done.\n",
            "Resolving deltas: 100% (1913/1913), done.\n",
            "Processing ./MDSINE2\n",
            "\u001b[33m  DEPRECATION: A future pip version will change local packages to be built in-place without first copying to a temporary directory. We recommend you use --use-feature=in-tree-build to test your packages with this new behavior before it becomes the default.\n",
            "   pip 21.3 will remove support for this functionality. You can find discussion regarding this at https://github.com/pypa/pip/issues/7555.\u001b[0m\n",
            "Requirement already satisfied: numpy>=1.19.4 in /usr/local/lib/python3.7/dist-packages (from mdsine2==0.4.5) (1.19.5)\n",
            "Requirement already satisfied: pandas>=1.1.4 in /usr/local/lib/python3.7/dist-packages (from mdsine2==0.4.5) (1.1.5)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from mdsine2==0.4.5) (1.4.1)\n",
            "Collecting matplotlib>=3.3.1\n",
            "  Downloading matplotlib-3.5.1-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.whl (11.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 11.2 MB 5.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: sklearn in /usr/local/lib/python3.7/dist-packages (from mdsine2==0.4.5) (0.0)\n",
            "Requirement already satisfied: seaborn>=0.11.0 in /usr/local/lib/python3.7/dist-packages (from mdsine2==0.4.5) (0.11.2)\n",
            "Collecting h5py==2.9.0\n",
            "  Downloading h5py-2.9.0-cp37-cp37m-manylinux1_x86_64.whl (2.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.8 MB 46.1 MB/s \n",
            "\u001b[?25hCollecting psutil==5.7.3\n",
            "  Downloading psutil-5.7.3.tar.gz (465 kB)\n",
            "\u001b[K     |████████████████████████████████| 465 kB 36.4 MB/s \n",
            "\u001b[?25hCollecting networkx==2.3\n",
            "  Downloading networkx-2.3.zip (1.7 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.7 MB 37.8 MB/s \n",
            "\u001b[?25hCollecting numba==0.52\n",
            "  Downloading numba-0.52.0-cp37-cp37m-manylinux2014_x86_64.whl (3.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.2 MB 34.6 MB/s \n",
            "\u001b[?25hCollecting biopython==1.78\n",
            "  Downloading biopython-1.78-cp37-cp37m-manylinux1_x86_64.whl (2.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.3 MB 39.3 MB/s \n",
            "\u001b[?25hCollecting treeswift==1.1.14\n",
            "  Downloading treeswift-1.1.14-py2.py3-none-any.whl (32 kB)\n",
            "Collecting py2cytoscape==0.7.1\n",
            "  Downloading py2cytoscape-0.7.1.tar.gz (57 kB)\n",
            "\u001b[K     |████████████████████████████████| 57 kB 5.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from mdsine2==0.4.5) (4.62.3)\n",
            "Collecting PyQt5\n",
            "  Downloading PyQt5-5.15.6-cp36-abi3-manylinux1_x86_64.whl (8.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 8.3 MB 23.6 MB/s \n",
            "\u001b[?25hCollecting ete3\n",
            "  Downloading ete3-3.1.2.tar.gz (4.7 MB)\n",
            "\u001b[K     |████████████████████████████████| 4.7 MB 42.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from h5py==2.9.0->mdsine2==0.4.5) (1.15.0)\n",
            "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.7/dist-packages (from networkx==2.3->mdsine2==0.4.5) (4.4.2)\n",
            "Collecting llvmlite<0.36,>=0.35.0\n",
            "  Downloading llvmlite-0.35.0-cp37-cp37m-manylinux2010_x86_64.whl (25.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 25.3 MB 1.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from numba==0.52->mdsine2==0.4.5) (57.4.0)\n",
            "Requirement already satisfied: pydot in /usr/local/lib/python3.7/dist-packages (from py2cytoscape==0.7.1->mdsine2==0.4.5) (1.3.0)\n",
            "Requirement already satisfied: pydotplus in /usr/local/lib/python3.7/dist-packages (from py2cytoscape==0.7.1->mdsine2==0.4.5) (2.0.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from py2cytoscape==0.7.1->mdsine2==0.4.5) (2.23.0)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.7/dist-packages (from py2cytoscape==0.7.1->mdsine2==0.4.5) (3.0.6)\n",
            "Collecting python-igraph\n",
            "  Downloading python-igraph-0.9.8.tar.gz (9.5 kB)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=3.3.1->mdsine2==0.4.5) (2.8.2)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=3.3.1->mdsine2==0.4.5) (1.3.2)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=3.3.1->mdsine2==0.4.5) (7.1.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=3.3.1->mdsine2==0.4.5) (0.11.0)\n",
            "Collecting fonttools>=4.22.0\n",
            "  Downloading fonttools-4.28.5-py3-none-any.whl (890 kB)\n",
            "\u001b[K     |████████████████████████████████| 890 kB 34.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=3.3.1->mdsine2==0.4.5) (21.3)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas>=1.1.4->mdsine2==0.4.5) (2018.9)\n",
            "Collecting PyQt5-Qt5>=5.15.2\n",
            "  Downloading PyQt5_Qt5-5.15.2-py3-none-manylinux2014_x86_64.whl (59.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 59.9 MB 1.3 MB/s \n",
            "\u001b[?25hCollecting PyQt5-sip<13,>=12.8\n",
            "  Downloading PyQt5_sip-12.9.0-cp37-cp37m-manylinux1_x86_64.whl (317 kB)\n",
            "\u001b[K     |████████████████████████████████| 317 kB 33.1 MB/s \n",
            "\u001b[?25hCollecting igraph==0.9.8\n",
            "  Downloading igraph-0.9.8-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (3.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.2 MB 57.4 MB/s \n",
            "\u001b[?25hCollecting texttable>=1.6.2\n",
            "  Downloading texttable-1.6.4-py2.py3-none-any.whl (10 kB)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->py2cytoscape==0.7.1->mdsine2==0.4.5) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->py2cytoscape==0.7.1->mdsine2==0.4.5) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->py2cytoscape==0.7.1->mdsine2==0.4.5) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->py2cytoscape==0.7.1->mdsine2==0.4.5) (2021.10.8)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from sklearn->mdsine2==0.4.5) (1.0.1)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->sklearn->mdsine2==0.4.5) (1.1.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->sklearn->mdsine2==0.4.5) (3.0.0)\n",
            "Building wheels for collected packages: mdsine2, networkx, psutil, py2cytoscape, ete3, python-igraph\n",
            "  Building wheel for mdsine2 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for mdsine2: filename=mdsine2-0.4.5-cp37-cp37m-linux_x86_64.whl size=331225 sha256=375f54a2313a6adbff752b64fe0afad5739a6ab8e3dd452329d5d5253bad0880\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-_ff0h7mi/wheels/b7/19/91/a6396303d26cbb96faa55fdede89eb0dbe3c598d2306ddb8b8\n",
            "  Building wheel for networkx (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for networkx: filename=networkx-2.3-py2.py3-none-any.whl size=1556009 sha256=ee54f03eceb4372ce81cb55b7d489bf88778fb5a25bd570afaf9f3654bcba7b1\n",
            "  Stored in directory: /root/.cache/pip/wheels/44/e6/b8/4efaab31158e9e9ca9ed80b11f6b11130bac9a9672b3cbbeaf\n",
            "  Building wheel for psutil (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for psutil: filename=psutil-5.7.3-cp37-cp37m-linux_x86_64.whl size=285277 sha256=42fbd22f6c25161f7e2a4a29f218975102c2507a1cccf86f86133508c717938c\n",
            "  Stored in directory: /root/.cache/pip/wheels/f0/4b/57/d037639271e326da3e80e0ddc37bd3d5da7bbf48b3173be557\n",
            "  Building wheel for py2cytoscape (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for py2cytoscape: filename=py2cytoscape-0.7.1-py3-none-any.whl size=78829 sha256=7e2ad6e7177b8354d942065d7b842f7d9d7a845f943d3f89299f7e117f744b14\n",
            "  Stored in directory: /root/.cache/pip/wheels/17/d0/68/c5e4584aff90e7529b55fd9c7b8de97f4056ab615e91a65799\n",
            "  Building wheel for ete3 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for ete3: filename=ete3-3.1.2-py3-none-any.whl size=2273013 sha256=4961bf4561300f5eb146659b89ee79b84fab9800cd87b19e94770a01732ae852\n",
            "  Stored in directory: /root/.cache/pip/wheels/17/fd/e2/6ac384d8c2484789304657dde01b96d7ab83f4f1dd96d266df\n",
            "  Building wheel for python-igraph (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for python-igraph: filename=python_igraph-0.9.8-py3-none-any.whl size=9070 sha256=ca3325cc0144b8f8c277250f48fcd4e85e365a00125acb9c15ea5e4f1e9dc317\n",
            "  Stored in directory: /root/.cache/pip/wheels/15/86/ef/b8bcdfbcb1c489771ad256c7cd1eb4971cdb7f3f670938b798\n",
            "Successfully built mdsine2 networkx psutil py2cytoscape ete3 python-igraph\n",
            "Installing collected packages: texttable, igraph, fonttools, python-igraph, PyQt5-sip, PyQt5-Qt5, networkx, matplotlib, llvmlite, treeswift, PyQt5, py2cytoscape, psutil, numba, h5py, ete3, biopython, mdsine2\n",
            "  Attempting uninstall: networkx\n",
            "    Found existing installation: networkx 2.6.3\n",
            "    Uninstalling networkx-2.6.3:\n",
            "      Successfully uninstalled networkx-2.6.3\n",
            "  Attempting uninstall: matplotlib\n",
            "    Found existing installation: matplotlib 3.2.2\n",
            "    Uninstalling matplotlib-3.2.2:\n",
            "      Successfully uninstalled matplotlib-3.2.2\n",
            "  Attempting uninstall: llvmlite\n",
            "    Found existing installation: llvmlite 0.34.0\n",
            "    Uninstalling llvmlite-0.34.0:\n",
            "      Successfully uninstalled llvmlite-0.34.0\n",
            "  Attempting uninstall: psutil\n",
            "    Found existing installation: psutil 5.4.8\n",
            "    Uninstalling psutil-5.4.8:\n",
            "      Successfully uninstalled psutil-5.4.8\n",
            "  Attempting uninstall: numba\n",
            "    Found existing installation: numba 0.51.2\n",
            "    Uninstalling numba-0.51.2:\n",
            "      Successfully uninstalled numba-0.51.2\n",
            "  Attempting uninstall: h5py\n",
            "    Found existing installation: h5py 3.1.0\n",
            "    Uninstalling h5py-3.1.0:\n",
            "      Successfully uninstalled h5py-3.1.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "albumentations 0.1.12 requires imgaug<0.2.7,>=0.2.5, but you have imgaug 0.2.9 which is incompatible.\u001b[0m\n",
            "Successfully installed PyQt5-5.15.6 PyQt5-Qt5-5.15.2 PyQt5-sip-12.9.0 biopython-1.78 ete3-3.1.2 fonttools-4.28.5 h5py-2.9.0 igraph-0.9.8 llvmlite-0.35.0 matplotlib-3.5.1 mdsine2-0.4.5 networkx-2.3 numba-0.52.0 psutil-5.7.3 py2cytoscape-0.7.1 python-igraph-0.9.8 texttable-1.6.4 treeswift-1.1.14\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "matplotlib",
                  "mpl_toolkits",
                  "psutil"
                ]
              }
            }
          },
          "metadata": {}
        }
      ],
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "sRmP6tn63_dd",
        "outputId": "6c23408f-f22a-465a-b530-10840aef7f72"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install wget\n",
        "!pip install zenodo-get\n",
        "!pip install scikit-bio\n",
        "!pip install tables==3.6.1 --force-reinstall"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting wget\n",
            "  Downloading wget-3.2.zip (10 kB)\n",
            "Building wheels for collected packages: wget\n",
            "  Building wheel for wget (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for wget: filename=wget-3.2-py3-none-any.whl size=9672 sha256=0ffe17f853c4cda51bc1d32fcea632d02d6fe979955aa0276ed694f4223ba1cf\n",
            "  Stored in directory: /root/.cache/pip/wheels/a1/b6/7c/0e63e34eb06634181c63adacca38b79ff8f35c37e3c13e3c02\n",
            "Successfully built wget\n",
            "Installing collected packages: wget\n",
            "Successfully installed wget-3.2\n",
            "Collecting zenodo-get\n",
            "  Downloading zenodo_get-1.3.4-py2.py3-none-any.whl (17 kB)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from zenodo-get) (2.23.0)\n",
            "Requirement already satisfied: wget in /usr/local/lib/python3.7/dist-packages (from zenodo-get) (3.2)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->zenodo-get) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->zenodo-get) (2021.10.8)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->zenodo-get) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->zenodo-get) (1.24.3)\n",
            "Installing collected packages: zenodo-get\n",
            "Successfully installed zenodo-get-1.3.4\n",
            "Collecting scikit-bio\n",
            "  Downloading scikit-bio-0.5.6.tar.gz (8.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 8.4 MB 4.3 MB/s \n",
            "\u001b[?25hCollecting lockfile>=0.10.2\n",
            "  Downloading lockfile-0.12.2-py2.py3-none-any.whl (13 kB)\n",
            "Requirement already satisfied: CacheControl>=0.11.5 in /usr/local/lib/python3.7/dist-packages (from scikit-bio) (0.12.10)\n",
            "Requirement already satisfied: decorator>=3.4.2 in /usr/local/lib/python3.7/dist-packages (from scikit-bio) (4.4.2)\n",
            "Requirement already satisfied: IPython>=3.2.0 in /usr/local/lib/python3.7/dist-packages (from scikit-bio) (5.5.0)\n",
            "Requirement already satisfied: matplotlib>=1.4.3 in /usr/local/lib/python3.7/dist-packages (from scikit-bio) (3.5.1)\n",
            "Requirement already satisfied: natsort>=4.0.3 in /usr/local/lib/python3.7/dist-packages (from scikit-bio) (5.5.0)\n",
            "Requirement already satisfied: numpy>=1.9.2 in /usr/local/lib/python3.7/dist-packages (from scikit-bio) (1.19.5)\n",
            "Requirement already satisfied: pandas>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-bio) (1.1.5)\n",
            "Requirement already satisfied: scipy>=1.3.0 in /usr/local/lib/python3.7/dist-packages (from scikit-bio) (1.4.1)\n",
            "Collecting hdmedians>=0.13\n",
            "  Downloading hdmedians-0.14.2.tar.gz (7.6 kB)\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Installing backend dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "    Preparing wheel metadata ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: scikit-learn>=0.19.1 in /usr/local/lib/python3.7/dist-packages (from scikit-bio) (1.0.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from CacheControl>=0.11.5->scikit-bio) (2.23.0)\n",
            "Requirement already satisfied: msgpack>=0.5.2 in /usr/local/lib/python3.7/dist-packages (from CacheControl>=0.11.5->scikit-bio) (1.0.3)\n",
            "Requirement already satisfied: Cython>=0.23 in /usr/local/lib/python3.7/dist-packages (from hdmedians>=0.13->scikit-bio) (0.29.24)\n",
            "Requirement already satisfied: simplegeneric>0.8 in /usr/local/lib/python3.7/dist-packages (from IPython>=3.2.0->scikit-bio) (0.8.1)\n",
            "Requirement already satisfied: prompt-toolkit<2.0.0,>=1.0.4 in /usr/local/lib/python3.7/dist-packages (from IPython>=3.2.0->scikit-bio) (1.0.18)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.7/dist-packages (from IPython>=3.2.0->scikit-bio) (2.6.1)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.7/dist-packages (from IPython>=3.2.0->scikit-bio) (0.7.5)\n",
            "Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.7/dist-packages (from IPython>=3.2.0->scikit-bio) (5.1.1)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.7/dist-packages (from IPython>=3.2.0->scikit-bio) (57.4.0)\n",
            "Requirement already satisfied: pexpect in /usr/local/lib/python3.7/dist-packages (from IPython>=3.2.0->scikit-bio) (4.8.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=1.4.3->scikit-bio) (21.3)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=1.4.3->scikit-bio) (1.3.2)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=1.4.3->scikit-bio) (2.8.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=1.4.3->scikit-bio) (0.11.0)\n",
            "Requirement already satisfied: pyparsing>=2.2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=1.4.3->scikit-bio) (3.0.6)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=1.4.3->scikit-bio) (7.1.2)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=1.4.3->scikit-bio) (4.28.5)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas>=1.0.0->scikit-bio) (2018.9)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.7/dist-packages (from prompt-toolkit<2.0.0,>=1.0.4->IPython>=3.2.0->scikit-bio) (1.15.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.7/dist-packages (from prompt-toolkit<2.0.0,>=1.0.4->IPython>=3.2.0->scikit-bio) (0.2.5)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.19.1->scikit-bio) (3.0.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.19.1->scikit-bio) (1.1.0)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.7/dist-packages (from pexpect->IPython>=3.2.0->scikit-bio) (0.7.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->CacheControl>=0.11.5->scikit-bio) (2021.10.8)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->CacheControl>=0.11.5->scikit-bio) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->CacheControl>=0.11.5->scikit-bio) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->CacheControl>=0.11.5->scikit-bio) (3.0.4)\n",
            "Building wheels for collected packages: scikit-bio, hdmedians\n",
            "  Building wheel for scikit-bio (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for scikit-bio: filename=scikit_bio-0.5.6-cp37-cp37m-linux_x86_64.whl size=1456880 sha256=4a99b249c1507ffbaf64b9e8bada04749a17329562fdb3f0e071e86d74c404d1\n",
            "  Stored in directory: /root/.cache/pip/wheels/7e/fa/86/a8b3b3b1187f0b0997fca40cdb7dd0d81a57ff061010e4464d\n",
            "  Building wheel for hdmedians (PEP 517) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for hdmedians: filename=hdmedians-0.14.2-cp37-cp37m-linux_x86_64.whl size=453200 sha256=2a7ca9e67104db2c98fd258dc137d5b1f1b91e68a98e03db05e5580d17a8d4b5\n",
            "  Stored in directory: /root/.cache/pip/wheels/56/5d/28/fb40426fbf6a8c3af88376a227130bbdf81e00177123e1398e\n",
            "Successfully built scikit-bio hdmedians\n",
            "Installing collected packages: lockfile, hdmedians, scikit-bio\n",
            "Successfully installed hdmedians-0.14.2 lockfile-0.12.2 scikit-bio-0.5.6\n",
            "Collecting tables==3.6.1\n",
            "  Downloading tables-3.6.1-cp37-cp37m-manylinux1_x86_64.whl (4.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 4.3 MB 5.4 MB/s \n",
            "\u001b[?25hCollecting numexpr>=2.6.2\n",
            "  Downloading numexpr-2.8.1-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (379 kB)\n",
            "\u001b[K     |████████████████████████████████| 379 kB 65.2 MB/s \n",
            "\u001b[?25hCollecting numpy>=1.9.3\n",
            "  Downloading numpy-1.21.5-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (15.7 MB)\n",
            "\u001b[K     |████████████████████████████████| 15.7 MB 43.7 MB/s \n",
            "\u001b[?25hCollecting packaging\n",
            "  Downloading packaging-21.3-py3-none-any.whl (40 kB)\n",
            "\u001b[K     |████████████████████████████████| 40 kB 5.9 MB/s \n",
            "\u001b[?25hCollecting pyparsing!=3.0.5,>=2.0.2\n",
            "  Downloading pyparsing-3.0.6-py3-none-any.whl (97 kB)\n",
            "\u001b[K     |████████████████████████████████| 97 kB 8.1 MB/s \n",
            "\u001b[?25hInstalling collected packages: pyparsing, packaging, numpy, numexpr, tables\n",
            "  Attempting uninstall: pyparsing\n",
            "    Found existing installation: pyparsing 3.0.6\n",
            "    Uninstalling pyparsing-3.0.6:\n",
            "      Successfully uninstalled pyparsing-3.0.6\n",
            "  Attempting uninstall: packaging\n",
            "    Found existing installation: packaging 21.3\n",
            "    Uninstalling packaging-21.3:\n",
            "      Successfully uninstalled packaging-21.3\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 1.19.5\n",
            "    Uninstalling numpy-1.19.5:\n",
            "      Successfully uninstalled numpy-1.19.5\n",
            "  Attempting uninstall: numexpr\n",
            "    Found existing installation: numexpr 2.7.3\n",
            "    Uninstalling numexpr-2.7.3:\n",
            "      Successfully uninstalled numexpr-2.7.3\n",
            "  Attempting uninstall: tables\n",
            "    Found existing installation: tables 3.4.4\n",
            "    Uninstalling tables-3.4.4:\n",
            "      Successfully uninstalled tables-3.4.4\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "yellowbrick 1.3.post1 requires numpy<1.20,>=1.16.0, but you have numpy 1.21.5 which is incompatible.\n",
            "datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\n",
            "albumentations 0.1.12 requires imgaug<0.2.7,>=0.2.5, but you have imgaug 0.2.9 which is incompatible.\u001b[0m\n",
            "Successfully installed numexpr-2.8.1 numpy-1.21.5 packaging-21.3 pyparsing-3.0.6 tables-3.6.1\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "numpy",
                  "pyparsing"
                ]
              }
            }
          },
          "metadata": {}
        }
      ],
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "w37zPcAr35ZX",
        "outputId": "89b3e5f2-486f-40cb-a807-e0a807f93d52"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Zenodo file retrieval\n",
        "\n",
        "The relevant files needed to make the figures are saved in zenodo. "
      ],
      "metadata": {
        "id": "gvxfwJ7cQF0s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://zenodo.org/record/5781848/files/forward_sims.tgz\n",
        "!wget https://zenodo.org/record/5781848/files/mixed_prior_fixed.tgz\n",
        "!wget https://zenodo.org/record/5781848/files/mixed_prior_unfixed.tgz\n",
        "!wget https://zenodo.org/record/5781848/files/other_files.tgz"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2021-12-20 20:58:47--  https://zenodo.org/record/5781848/files/forward_sims.tgz\n",
            "Resolving zenodo.org (zenodo.org)... 137.138.76.77\n",
            "Connecting to zenodo.org (zenodo.org)|137.138.76.77|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 5183489132 (4.8G) [application/octet-stream]\n",
            "Saving to: ‘forward_sims.tgz’\n",
            "\n",
            "forward_sims.tgz    100%[===================>]   4.83G  23.7MB/s    in 7m 1s   \n",
            "\n",
            "2021-12-20 21:05:49 (11.7 MB/s) - ‘forward_sims.tgz’ saved [5183489132/5183489132]\n",
            "\n",
            "--2021-12-20 21:05:49--  https://zenodo.org/record/5781848/files/mixed_prior_fixed.tgz\n",
            "Resolving zenodo.org (zenodo.org)... 137.138.76.77\n",
            "Connecting to zenodo.org (zenodo.org)|137.138.76.77|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 6286873326 (5.9G) [application/octet-stream]\n",
            "Saving to: ‘mixed_prior_fixed.tgz’\n",
            "\n",
            "mixed_prior_fixed.t  27%[====>               ]   1.63G  22.1MB/s    eta 3m 11s "
          ]
        }
      ],
      "execution_count": null,
      "metadata": {
        "id": "aMKy8vLG3t4_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "67dd4edd-7781-4cb3-ce86-a452c9436c34"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#use if wget does not work\n",
        "#!zenodo_get -d 10.5281/zenodo.5781391"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "id": "FrPWLmik2v6X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title unzip the .tgz files\n",
        "!tar -xzvf \"mixed_prior_fixed.tgz\" \n",
        "!tar -xzvf \"mixed_prior_unfixed.tgz\" \n",
        "!tar -xzvf \"forward_sims.tgz\" \n",
        "!tar -xzvf \"other_files.tgz\" "
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "id": "r49tYg-y3wbw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone --branch sawal_final_changes https://github.com/gerberlab/MDSINE2_Paper"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "id": "czMvwBGV39IO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/MDSINE2_Paper/analysis/\n",
        "%pwd\n",
        "%matplotlib notebook\n",
        "import matplotlib.pyplot as plt \n",
        "from pathlib import Path\n",
        "import os\n",
        "\n",
        "saveloc = \"output/gibson/plots\"\n",
        "os.makedirs(saveloc, exist_ok=True)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "id": "A-BEV3_k4B27"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Figure 2\n",
        "\n",
        "The figure is made in two steps. First, we plot all the parts but the heatmap showing deseq results. Also, the animations in panel A of the figure are not visible. They are added manually using Adobe Illustrator. "
      ],
      "metadata": {
        "id": "7perTWNDQ0g2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python gibson_inference/figures/figure2.py \\\n",
        "       -file1 \"gibson_inference/figures/preprocessed_all/gibson_healthy_agg_taxa.pkl\" \\\n",
        "       -file2 \"gibson_inference/figures/preprocessed_all/gibson_uc_agg_taxa.pkl\" \\\n",
        "       -file3 \"gibson_inference/figures/preprocessed_all/gibson_inoculum_agg_taxa.pkl\" \\\n",
        "       -o_loc \"output/gibson/plots\""
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "id": "55oba8CC4EG4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Figure 2 Heatmap \n",
        "\n",
        "The output files are called mat_order_high_ss and mat_order_low_ss; the former and latter files illustrate the deseq results for order/family whose relative abundances are >0.5 and <0.5% respectively. The heatmaps are compiled into the paper version manually using Adobe Illustrator. \n"
      ],
      "metadata": {
        "id": "PQ-V8Ggu5Lj6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python gibson_inference/figures/deseq_heatmap_ss.py \\\n",
        "    -loc \"gibson_inference/figures/figure2_files\" \\\n",
        "    -abund \"high\" \\\n",
        "    -txt \"abundant_species\" \\\n",
        "    -taxo \"order\" \\\n",
        "    -o \"mat_order_high_ss\" \\\n",
        "    -o_loc \"output/gibson/plots\"\n",
        "\n",
        "\n",
        "!python gibson_inference/figures/deseq_heatmap_ss.py \\\n",
        "    -loc \"gibson_inference/figures/figure2_files\" \\\n",
        "    -abund \"low\" \\\n",
        "    -txt \"abundant_species\" \\\n",
        "    -taxo \"order\" \\\n",
        "    -o \"mat_order_low_ss\" \\\n",
        "    -o_loc \"output/gibson/plots\"\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "id": "wfsh1Syz40eo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Figure 3 "
      ],
      "metadata": {
        "id": "Bqt56jBJRm5P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python gibson_inference/figures/figure3.py \\\n",
        "    --mdsine_path \"/content/forward_sims/\"\\\n",
        "    --clv_elas_path \"/content/clv_results/results_rel_elastic/\"\\\n",
        "    --clv_ridge_path \"/content/clv_results/results_rel_ridge/\"\\\n",
        "    --glv_elas_path \"/content/clv_results/results_abs_elastic/\"\\\n",
        "    --glv_ridge_path \"/content/clv_results/results_abs_ridge/forward_sims_abs_ridge/\"\\\n",
        "    --output_path \"output/gibson/plots/\""
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "id": "fA0o2aMO4TIb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Figure 4\n",
        "\n",
        "All sub-plots except the network diagrams for Healthy and Dysbiotic Cohorts are made. The networks are created using cytoscape and added to the figure manually using Adobe Illustrator.  "
      ],
      "metadata": {
        "id": "2V5nTum5Rwhx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python gibson_inference/figures/figure4.py \\\n",
        "    --chain_healthy \"/content/mixed_prior_fixed/healthy-seed0-mixed/mcmc.pkl\" \\\n",
        "    --chain_uc \"/content/mixed_prior_fixed/uc-seed0-mixed/mcmc.pkl\" \\\n",
        "    --tree_fname 'files/phylogenetic_placement_OTUs/phylogenetic_tree_only_query.nhx' \\\n",
        "    --study_healthy \"output/gibson/preprocessed/gibson_healthy_agg_taxa.pkl\" \\\n",
        "    --study_uc \"output/gibson/preprocessed/gibson_uc_agg_taxa.pkl\" \\\n",
        "    --study_inoc \"output/gibson/preprocessed/gibson_inoculum_agg_taxa.pkl\" \\\n",
        "    --detected_study_healthy \"gibson_inference/figures/preprocessed_all/gibson_healthy_agg_taxa_filtered3.pkl\" \\\n",
        "    --detected_study_uc \"gibson_inference/figures/preprocessed_all/gibson_uc_agg_taxa_filtered3.pkl\" \\\n",
        "    --output_loc \"output/gibson/plots\""
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "id": "-U15N0oC41E7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Figure 5\n",
        "\n",
        "This figure shows the Phylogenetic Neighborhood Analysis result, (Figure 5B).\n",
        "The cartoon (Figure 5A) is created separately."
      ],
      "metadata": {
        "id": "sZK-5UuxSOHK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python gibson_inference/figures/figure5.py \\\n",
        "    -file1 \"/content/coarsening/distance.csv\" \\\n",
        "    -file2 \"/content/coarsening/arithmetic_mean_data.csv\" \\\n",
        "    -file3 \"/content/coarsening/arithmetic_mean_null_all.csv\" \\\n",
        "    -o_loc \"output/gibson/plots\""
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "id": "2frezFvt5mfE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Figure 6"
      ],
      "metadata": {
        "id": "AHzKr7YAUlj-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Custom code necessary for rendering using pre-computed data."
      ],
      "metadata": {
        "id": "4qrUNlc9U121"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title\n",
        "import mdsine2 as md2\n",
        "from mdsine2.names import STRNAMES\n",
        "import numpy as np\n",
        "import scipy\n",
        "import scipy.stats\n",
        "import pandas as pd\n",
        "from pathlib import Path\n",
        "from tqdm.notebook import tqdm\n",
        "import seaborn as sns\n",
        "\n",
        "\n",
        "# COLORS\n",
        "_default_colors = sns.color_palette()\n",
        "_default_healthy_color = _default_colors[0]\n",
        "_default_uc_color = _default_colors[1]\n",
        "\n",
        "\n",
        "def stat_annotate(x1, x2, y, h, color, ax, lw=1.0, desc='*'):\n",
        "    ax.plot([x1, x1, x2, x2], [y, y+h, y+h, y], lw=lw, c=color)\n",
        "    ax.text((x1+x2)*.5, y+h, desc, ha='center', va='bottom', color=color)\n",
        "\n",
        "\n",
        "class PerturbationSimFigure():\n",
        "    \"\"\"Render figures for perturbation simulations. (Figures 6A,6B)\"\"\"\n",
        "\n",
        "    def __init__(self, data_dir: Path, healthy_color=_default_healthy_color, uc_color=_default_uc_color):\n",
        "        self.healthy_color = healthy_color\n",
        "        self.uc_color = uc_color\n",
        "\n",
        "        # DATA DIR\n",
        "        self.data_dir = data_dir\n",
        "\n",
        "        # ============ Preprocessing\n",
        "        print(\"Loading dataframes from disk.\")\n",
        "        healthy_random_pert_metadata_df = pd.read_hdf(\n",
        "            data_dir / 'healthy_metadata.h5', key=\"df\", mode=\"r\")\n",
        "        healthy_random_pert_fwsim_df = pd.read_hdf(\n",
        "            data_dir / 'healthy_fwsim.h5', key=\"df\", mode=\"r\"\n",
        "        )\n",
        "\n",
        "        uc_random_pert_metadata_df = pd.read_hdf(\n",
        "            data_dir / 'uc_metadata.h5', key=\"df\", mode=\"r\"\n",
        "        )\n",
        "        uc_random_pert_fwsim_df = pd.read_hdf(\n",
        "            data_dir / 'uc_fwsim.h5', key=\"df\", mode=\"r\"\n",
        "        )\n",
        "\n",
        "        print(\"Merging dataframes.\")\n",
        "        healthy_random_pert_merged_df = self.posthoc_random_pert_helper(healthy_random_pert_fwsim_df, healthy_random_pert_metadata_df)\n",
        "        uc_random_pert_merged_df = self.posthoc_random_pert_helper(uc_random_pert_fwsim_df, uc_random_pert_metadata_df)\n",
        "\n",
        "        print(\"Computing difference levels.\")\n",
        "        self.random_pert_concat_df = self.random_pert_diff_figure_df(healthy_random_pert_merged_df, uc_random_pert_merged_df)\n",
        "\n",
        "        print(\"Computing diversities.\")\n",
        "        self.random_pert_diversity_df, self.healthy_random_pert_baseline_diversity, self.uc_random_pert_baseline_diversity = self.precompute_diversities(\n",
        "            healthy_random_pert_fwsim_df, uc_random_pert_fwsim_df\n",
        "        )\n",
        "\n",
        "        print(\"Finished initialization.\")\n",
        "\n",
        "    @staticmethod\n",
        "    def posthoc_random_pert_helper(fwsim: pd.DataFrame, metadata: pd.DataFrame):\n",
        "        merged_df = fwsim.loc[(fwsim[\"PerturbedFrac\"] != 0.0), :].merge(\n",
        "            fwsim.loc[(fwsim[\"PerturbedFrac\"] == 0.0), [\"OTU\", \"SteadyState\", \"Died\", \"SampleIdx\"]],\n",
        "            left_on=[\"OTU\", \"SampleIdx\"],\n",
        "            right_on=[\"OTU\", \"SampleIdx\"],\n",
        "            how=\"inner\",\n",
        "            suffixes=[\"\", \"Base\"]\n",
        "        ).merge(\n",
        "            metadata.loc[\n",
        "                :,\n",
        "                [\"OTU\", \"PerturbedFrac\", \"Perturbation\", \"Trial\", \"IsPerturbed\"]\n",
        "            ],\n",
        "            left_on=[\"OTU\", \"PerturbedFrac\", \"Perturbation\", \"Trial\"],\n",
        "            right_on=[\"OTU\", \"PerturbedFrac\", \"Perturbation\", \"Trial\"]\n",
        "        ).set_index([\"OTU\", \"PerturbedFrac\", \"Perturbation\", \"Trial\", \"SampleIdx\"])\n",
        "\n",
        "        merged_df[\"SteadyStateDiff\"] = np.abs(np.log10(merged_df[\"SteadyState\"] + 1e5) - np.log10(merged_df[\"SteadyStateBase\"] + 1e5))\n",
        "\n",
        "        return merged_df\n",
        "\n",
        "    @staticmethod\n",
        "    def random_pert_diff_figure_df(healthy_merged_df: pd.DataFrame, uc_merged_df: pd.DataFrame, perturbation=-2.0):\n",
        "        #   OTU \tPerturbedFrac \tPerturbation \tTrial \tSampleIdx\n",
        "\n",
        "        healthy_agg_df = healthy_merged_df.loc[\n",
        "            (slice(None), slice(None), perturbation, slice(None), slice(None)),\n",
        "            [\"SteadyStateDiff\"]\n",
        "        ].groupby(\n",
        "            level=[1, 2, 3, 4]  # \"PerturbedFrac\", \"Perturbation\", \"Trial\", \"SampleIdx\"\n",
        "        ).mean().groupby(\n",
        "            level=[0, 1, 2]  # \"PerturbedFrac\", \"Perturbation\", \"Trial\"\n",
        "        ).mean()\n",
        "\n",
        "        uc_agg_df = uc_merged_df.loc[\n",
        "            (slice(None), slice(None), perturbation, slice(None), slice(None)),\n",
        "            [\"SteadyStateDiff\"]\n",
        "        ].groupby(\n",
        "            level=[1, 2, 3, 4]  # \"PerturbedFrac\", \"Perturbation\", \"Trial\", \"SampleIdx\"\n",
        "        ).mean().groupby(\n",
        "            level=[0, 1, 2]  # \"PerturbedFrac\", \"Perturbation\", \"Trial\"\n",
        "        ).mean()\n",
        "\n",
        "        healthy_agg_df[\"Dataset\"] = \"Healthy\"\n",
        "        uc_agg_df[\"Dataset\"] = \"UC\"\n",
        "        concat_df = pd.concat([\n",
        "            healthy_agg_df.reset_index(),\n",
        "            uc_agg_df.reset_index()\n",
        "        ])\n",
        "\n",
        "        concat_df[\"key\"] = r'$\\alpha$:' + concat_df[\"PerturbedFrac\"].astype(str) + \"\\nPert:\" + concat_df[\"Perturbation\"].astype(str)\n",
        "        return concat_df\n",
        "\n",
        "    @staticmethod\n",
        "    def precompute_diversities(healthy_fwsim_df, uc_fwsim_df, perturbation=-2.0):\n",
        "        def agg(x):\n",
        "            p = x[\"SteadyState\"].to_numpy()\n",
        "            u = np.ones(p.shape[0])\n",
        "            return scipy.stats.entropy(p) / scipy.stats.entropy(u)\n",
        "\n",
        "        # ======= Altered\n",
        "        healthy_diversity = healthy_fwsim_df.loc[\n",
        "            (healthy_fwsim_df[\"PerturbedFrac\"] != 0.0) & (healthy_fwsim_df[\"Perturbation\"] == perturbation),\n",
        "            [\"Trial\", \"SampleIdx\", \"SteadyState\", \"PerturbedFrac\"]\n",
        "        ].groupby([\"PerturbedFrac\", \"Trial\", \"SampleIdx\"]).apply(\n",
        "            agg\n",
        "        ).groupby(level=[0, 1]).mean()\n",
        "        healthy_diversity = pd.DataFrame({\"Diversity\": healthy_diversity})\n",
        "        healthy_diversity[\"Dataset\"] = \"Healthy\"\n",
        "\n",
        "        uc_diversity = uc_fwsim_df.loc[\n",
        "            (uc_fwsim_df[\"PerturbedFrac\"] != 0.0) & (uc_fwsim_df[\"Perturbation\"] == perturbation),\n",
        "            [\"Trial\", \"SampleIdx\", \"SteadyState\", \"PerturbedFrac\"]\n",
        "        ].groupby([\"PerturbedFrac\", \"Trial\", \"SampleIdx\"]).apply(\n",
        "            agg\n",
        "        ).groupby(level=[0, 1]).mean()\n",
        "        uc_diversity = pd.DataFrame({\"Diversity\": uc_diversity})\n",
        "        uc_diversity[\"Dataset\"] = \"UC\"\n",
        "\n",
        "        diversities = pd.concat([healthy_diversity.reset_index(), uc_diversity.reset_index()]).reset_index()\n",
        "\n",
        "        # ======= Baselines\n",
        "        healthy_baseline_diversity = healthy_fwsim_df.loc[\n",
        "            healthy_fwsim_df[\"PerturbedFrac\"] == 0.0,\n",
        "            [\"SampleIdx\", \"SteadyState\"]\n",
        "        ].groupby(\"SampleIdx\").apply(\n",
        "            agg\n",
        "        ).mean()\n",
        "\n",
        "        uc_baseline_diversity = uc_fwsim_df.loc[\n",
        "            uc_fwsim_df[\"PerturbedFrac\"] == 0.0,\n",
        "            [\"SampleIdx\", \"SteadyState\"]\n",
        "        ].groupby(\"SampleIdx\").apply(\n",
        "            agg\n",
        "        ).mean()\n",
        "\n",
        "        return diversities, healthy_baseline_diversity, uc_baseline_diversity\n",
        "\n",
        "    def plot_deviations(\n",
        "        self,\n",
        "        ax,\n",
        "        ymin=0.0, ymax=0.35\n",
        "    ):\n",
        "        df = self.random_pert_concat_df\n",
        "        sns.swarmplot(x=\"PerturbedFrac\",\n",
        "                      y=\"SteadyStateDiff\",\n",
        "                      hue=\"Dataset\",\n",
        "                      ax=ax,\n",
        "                      data=df,\n",
        "                      palette={\"Healthy\": self.healthy_color, \"UC\": self.uc_color},\n",
        "                      size=3,\n",
        "                      dodge=True)\n",
        "\n",
        "        sns.boxplot(\n",
        "            data=df,\n",
        "            x=\"PerturbedFrac\", y=\"SteadyStateDiff\",\n",
        "            hue=\"Dataset\",\n",
        "            whis=[2.5, 97.5],\n",
        "            ax=ax,\n",
        "            showfliers=False,\n",
        "            palette={\"Healthy\": self.healthy_color, \"UC\": self.uc_color},\n",
        "            boxprops=dict(alpha=.4)\n",
        "        )\n",
        "\n",
        "        ax.set_ylim([ymin, ymax])\n",
        "\n",
        "        # Axis labels\n",
        "        ax.set_xlabel(\"Fraction of OTUs perturbed\")\n",
        "        ax.set_ylabel(\"Difference from Baseline Steady State\")\n",
        "\n",
        "        # =========== P-values + Benjamini-Hochberg correction\n",
        "        df_healthy = df.loc[df[\"Dataset\"] == \"Healthy\", [\"PerturbedFrac\", \"SteadyStateDiff\"]]\n",
        "        df_uc = df.loc[df[\"Dataset\"] == \"UC\", [\"PerturbedFrac\", \"SteadyStateDiff\"]]\n",
        "        df_merged = df_healthy.merge(df_uc, on=\"PerturbedFrac\", how=\"inner\", suffixes=[\"Healthy\", \"UC\"])\n",
        "\n",
        "        # Compute statistic (raw p-values)\n",
        "        def fn(tbl):\n",
        "            u = scipy.stats.mannwhitneyu(tbl[\"SteadyStateDiffHealthy\"], tbl[\"SteadyStateDiffUC\"], alternative=\"less\")\n",
        "            return u\n",
        "\n",
        "        pvalues = df_merged.groupby(\"PerturbedFrac\").apply(fn)\n",
        "        pvalues_df = pd.DataFrame({\"pvalue\": pvalues.sort_values()})\n",
        "\n",
        "        # Apply BH correction\n",
        "        p_adjusted = []\n",
        "        p_adj_prev = 0.0\n",
        "        for i, (index, row) in enumerate(pvalues_df.iterrows()):\n",
        "            p_adj = row[\"pvalue\"].pvalue * pvalues_df.shape[0] / (i+1)\n",
        "            p_adj = min(max(p_adj, p_adj_prev), 1)\n",
        "            p_adjusted.append(p_adj)\n",
        "            p_adj_prev = p_adj\n",
        "\n",
        "        pvalues_df[\"pvalue_adj\"] = p_adjusted\n",
        "        pvalues_df = pvalues_df.sort_values(\"PerturbedFrac\").reset_index()\n",
        "        sig_indices = pvalues_df.index[pvalues_df[\"pvalue_adj\"] <= 1e-3]\n",
        "\n",
        "        print(\"Pvalues for deviations\")\n",
        "        display(pvalues_df)\n",
        "\n",
        "    def plot_diversity(\n",
        "        self,\n",
        "        ax\n",
        "    ):\n",
        "        diversity_df = self.random_pert_diversity_df\n",
        "        healthy_baseline = self.healthy_random_pert_baseline_diversity\n",
        "        uc_baseline = self.uc_random_pert_baseline_diversity\n",
        "\n",
        "        sns.swarmplot(x=\"PerturbedFrac\",\n",
        "                      y=\"Diversity\",\n",
        "                      hue=\"Dataset\",\n",
        "                      ax=ax,\n",
        "                      data=diversity_df,\n",
        "                      palette={\"Healthy\": self.healthy_color, \"UC\": self.uc_color},\n",
        "                      size=3,\n",
        "                      dodge=True)\n",
        "\n",
        "        sns.boxplot(\n",
        "            x=\"PerturbedFrac\",\n",
        "            hue=\"Dataset\",\n",
        "            y=\"Diversity\",\n",
        "            data=diversity_df,\n",
        "            ax=ax,\n",
        "            whis=[2.5, 97.5],\n",
        "            showfliers=False,\n",
        "            palette={\"Healthy\": self.healthy_color, \"UC\": self.uc_color},\n",
        "            boxprops=dict(alpha=.4)\n",
        "        )\n",
        "\n",
        "        ax.plot([-0.5, 7], [healthy_baseline] * 2, color='blue', linestyle='dashed')\n",
        "        ax.plot([-0.5, 7], [uc_baseline] * 2, color='orange', linestyle='dashed')\n",
        "\n",
        "        ax.set_ylabel(\"Diversity (Normalized Entropy)\")\n",
        "        ax.set_xlabel(\"Fraction of OTUs perturbed\")\n",
        "\n",
        "        # =========== P-values + Benjamini-Hochberg correction\n",
        "        df_healthy = diversity_df.loc[diversity_df[\"Dataset\"] == \"Healthy\", [\"PerturbedFrac\", \"Diversity\"]]\n",
        "        df_uc = diversity_df.loc[diversity_df[\"Dataset\"] == \"UC\", [\"PerturbedFrac\", \"Diversity\"]]\n",
        "        df_merged = df_healthy.merge(df_uc, on=\"PerturbedFrac\", how=\"inner\", suffixes=[\"Healthy\", \"UC\"])\n",
        "\n",
        "        # Compute statistic (raw p-values)\n",
        "        def fn(tbl):\n",
        "            u = scipy.stats.mannwhitneyu(tbl[\"DiversityHealthy\"], tbl[\"DiversityUC\"], alternative=\"greater\")\n",
        "            return u\n",
        "\n",
        "        pvalues = df_merged.groupby(\"PerturbedFrac\").apply(fn)\n",
        "        pvalues_df = pd.DataFrame({\"pvalue\": pvalues.sort_values()})\n",
        "\n",
        "        # Apply BH correction\n",
        "        p_adjusted = []\n",
        "        p_adj_prev = 0.0\n",
        "        for i, (index, row) in enumerate(pvalues_df.iterrows()):\n",
        "            p_adj = row[\"pvalue\"].pvalue * pvalues_df.shape[0] / (i+1)\n",
        "            p_adj = min(max(p_adj, p_adj_prev), 1)\n",
        "            p_adjusted.append(p_adj)\n",
        "            p_adj_prev = p_adj\n",
        "\n",
        "        pvalues_df[\"pvalue_adj\"] = p_adjusted\n",
        "        pvalues_df = pvalues_df.sort_values(\"PerturbedFrac\").reset_index()\n",
        "        sig_indices = pvalues_df.index[pvalues_df[\"pvalue_adj\"] <= 1e-3]\n",
        "\n",
        "        print(\"Pvalues for diversity\")\n",
        "        display(pvalues_df)\n",
        "\n",
        "\n",
        "class EigenvalueFigure():\n",
        "    def __init__(self, healthy_pickle_path, uc_pickle_path, healthy_color=_default_healthy_color, uc_color=_default_uc_color):\n",
        "        self.healthy_color = healthy_color\n",
        "        self.uc_color = uc_color\n",
        "\n",
        "        print(\"Computing Healthy dataset eigenvalues.\")\n",
        "        self.healthy_eig_X = self.compute_eigenvalues(healthy_pickle_path)\n",
        "\n",
        "        print(\"Computing D dataset eigenvalues.\")\n",
        "        self.uc_eig_X = self.compute_eigenvalues(uc_pickle_path)\n",
        "\n",
        "    def compute_eigenvalues(self, mcmc_pickle_path, upper_bound: float = 1e20):\n",
        "        # ================ Data loading\n",
        "        mcmc = md2.BaseMCMC.load(mcmc_pickle_path)\n",
        "        si_trace = -np.absolute(mcmc.graph[STRNAMES.SELF_INTERACTION_VALUE].get_trace_from_disk(section='posterior'))\n",
        "        interactions = mcmc.graph[STRNAMES.INTERACTIONS_OBJ].get_trace_from_disk(section='posterior')\n",
        "\n",
        "        interactions[np.isnan(interactions)] = 0\n",
        "        for i in range(len(mcmc.graph.data.taxa)):\n",
        "            interactions[:,i,i] = si_trace[:,i]\n",
        "\n",
        "        # ================ Eigenvalue computation\n",
        "        N = interactions.shape[0]\n",
        "        M = interactions.shape[1]\n",
        "        eigs = np.zeros(shape=(N, M), dtype=np.complex)\n",
        "        for i in tqdm(range(N)):  # range(arr.shape[0]):\n",
        "            matrix = interactions[i]\n",
        "\n",
        "            # only for interaction matrices\n",
        "            matrix = np.nan_to_num(matrix, nan=0.0)\n",
        "\n",
        "            slice_eigs = np.linalg.eigvals(matrix)\n",
        "\n",
        "            # Throw out samples where eigenvalues blow up\n",
        "            if np.sum(np.abs(slice_eigs) > upper_bound) > 0:\n",
        "                print(\"Upper bound threshold {th} passed for sample {i}; skipping.\".format(\n",
        "                    th=upper_bound,\n",
        "                    i=i\n",
        "                ))\n",
        "                continue\n",
        "\n",
        "            eigs[i, :] = slice_eigs\n",
        "\n",
        "        # Get real positive parts only.\n",
        "        eigs = eigs.real.flatten()\n",
        "        return eigs[eigs > 0]\n",
        "\n",
        "    def plot(self, ax, alpha: float = 0.7):\n",
        "        ####################################################\n",
        "        # Eigenvalue histogram.\n",
        "        ####################################################\n",
        "\n",
        "        bins = np.linspace(0, 5e-9, 45)\n",
        "        sns.histplot(self.uc_eig_X, ax=ax, bins=bins, label='Dysbiosis',\n",
        "                     alpha=alpha, color=self.uc_color)\n",
        "        sns.histplot(self.healthy_eig_X, ax=ax, bins=bins, label='Healthy',\n",
        "                     alpha=alpha, color=self.healthy_color)\n",
        "\n",
        "        ax.set_xlabel('Pos. Real Part of Eigenvalues', labelpad=20)\n",
        "        ax.set_ylabel('Total count with multiplicity')\n",
        "        ax.ticklabel_format(style=\"sci\", scilimits=(0,0), useMathText=True, useOffset=False)\n",
        "\n",
        "\n",
        "class CycleFigure():\n",
        "    def __init__(self, healthy_pickle_path, uc_pickle_path, healthy_color=_default_healthy_color, uc_color=_default_uc_color):\n",
        "        self.healthy_color = healthy_color\n",
        "        self.uc_color = uc_color\n",
        "\n",
        "        self.healthy_pickle_path = healthy_pickle_path\n",
        "        self.uc_pickle_path = uc_pickle_path\n",
        "\n",
        "        healthy_fixed_cluster = MdsineOutput(\n",
        "            \"Healthy\",\n",
        "            self.healthy_pickle_path\n",
        "        )\n",
        "        uc_fixed_cluster = MdsineOutput(\n",
        "            \"UC\",\n",
        "            self.uc_pickle_path\n",
        "        )\n",
        "\n",
        "        print(\"Computing cycles for Healthy dataset.\")\n",
        "        self.healthy_signed_cycles = self.compute_signed_statistics(\n",
        "            healthy_fixed_cluster.get_clustered_interactions()\n",
        "        )\n",
        "\n",
        "        print(\"Computing cycles for Dysbiotic dataset.\")\n",
        "        self.uc_signed_cycles = self.compute_signed_statistics(\n",
        "            uc_fixed_cluster.get_clustered_interactions()\n",
        "        )\n",
        "        self.n_samples = 10000\n",
        "\n",
        "    def compute_signed_statistics(self, interactions):\n",
        "        \"\"\"\n",
        "        Loop through each gibbs sample. For each gibbs sample, compute the number of cycles, assorted by sign.\n",
        "        (Does not tell us exactly which cycles appear frequently.)\n",
        "        \"\"\"\n",
        "        N = interactions.shape[0]\n",
        "        ans = {\n",
        "            '++': np.zeros(N),\n",
        "            '--': np.zeros(N),\n",
        "            '+-': np.zeros(N),\n",
        "            '+++': np.zeros(N),\n",
        "            '---': np.zeros(N),\n",
        "            '++-': np.zeros(N),\n",
        "            '--+': np.zeros(N)\n",
        "        }\n",
        "        for idx, mat in tqdm(enumerate(interactions), total=N):\n",
        "            signed_cycle_counts = self.count_signed_cycles(mat)\n",
        "            for sgn, counts in ans.items():\n",
        "                counts[idx] = signed_cycle_counts[sgn]\n",
        "        return ans\n",
        "\n",
        "    def count_signed_cycles(self, mat):\n",
        "        '''\n",
        "        Count length 2 and 3 cycles, given a particular interaction matrix (corresp. to a single gibbs sample).\n",
        "        '''\n",
        "        adj = np.copy(mat).T\n",
        "        plus_adj = np.zeros(shape=adj.shape, dtype=np.int)\n",
        "        plus_adj[adj > 0] = 1\n",
        "        minus_adj = np.zeros(shape=adj.shape, dtype=np.int)\n",
        "        minus_adj[adj < 0] = 1\n",
        "\n",
        "        return {\n",
        "            '++': self.count_cycles_with_sign(['++'], plus_adj, minus_adj) / 2,\n",
        "            '--': self.count_cycles_with_sign(['--'], plus_adj, minus_adj) / 2,\n",
        "            '+-': self.count_cycles_with_sign(['+-', '-+'], plus_adj, minus_adj) / 2,\n",
        "            '+++': self.count_cycles_with_sign(['+++'], plus_adj, minus_adj) / 3,\n",
        "            '---': self.count_cycles_with_sign(['---'], plus_adj, minus_adj) / 3,\n",
        "            '++-': self.count_cycles_with_sign(['++-', '+-+', '-++'], plus_adj, minus_adj) / 3,\n",
        "            '--+': self.count_cycles_with_sign(['--+', '-+-', '+--'], plus_adj, minus_adj) / 3,\n",
        "        }\n",
        "\n",
        "    @staticmethod\n",
        "    def count_cycles_with_sign(signs, plus, minus):\n",
        "        \"\"\"\n",
        "        Multiply adjacency matrices to count the number of cycles. Example: #(+-+) = Trace[(M+) * (M-) * (M+)]\n",
        "        \"\"\"\n",
        "        ans = 0\n",
        "        for pattern in signs:\n",
        "            M = np.eye(plus.shape[0])\n",
        "            for sign in pattern:\n",
        "                if sign == \"+\":\n",
        "                    M = M @ plus\n",
        "                elif sign == \"-\":\n",
        "                    M = M @ minus\n",
        "            ans = ans + np.sum(np.diag(M))\n",
        "        return ans\n",
        "\n",
        "    def plot(self, ax):\n",
        "        lengths = [2, 3]\n",
        "        signs = ['++', '--', '+-', '+++', '---', '++-', '--+']\n",
        "        sign_order = {\n",
        "            \"({})\".format(\" \".join(sgn)): i for i, sgn in enumerate(signs)\n",
        "        }\n",
        "        df = pd.DataFrame(columns=[\"Count\"],\n",
        "                          dtype=np.float,\n",
        "                          index=pd.MultiIndex.from_product(\n",
        "                              [signs, range(self.n_samples), [\"Healthy\", \"UC\"]],\n",
        "                              names=[\"Sign\", \"Index\", \"Dataset\"]\n",
        "                          ))\n",
        "\n",
        "        for pattern in signs:\n",
        "            df.loc[(pattern, slice(None), \"Healthy\")] = self.healthy_signed_cycles[pattern].reshape(-1, 1)\n",
        "            df.loc[(pattern, slice(None), \"UC\")] = self.uc_signed_cycles[pattern].reshape(-1, 1)\n",
        "\n",
        "        df = df.reset_index()\n",
        "        df[\"Sign\"] = df[\"Sign\"].map({\n",
        "            \"++\": \"(+ +)\",\n",
        "            \"--\": \"(- -)\",\n",
        "            \"+-\": \"(+ -)\",\n",
        "            \"+++\": \"(+ + +)\",\n",
        "            \"---\": \"(- - -)\",\n",
        "            \"++-\": \"(+ + -)\",\n",
        "            \"--+\": \"(- - +)\",\n",
        "        })\n",
        "\n",
        "        medianprops = dict(linestyle='--', linewidth=2.5)\n",
        "\n",
        "        sns.violinplot(x=\"Sign\",\n",
        "                       y=\"Count\",\n",
        "                       hue=\"Dataset\", data=df,\n",
        "                       ax=ax,\n",
        "                       scale=\"count\",\n",
        "                       cut=0,\n",
        "    #                    inner=\"quartile\",\n",
        "                       bw=0.5,\n",
        "                       palette={\"Healthy\": self.healthy_color, \"UC\": self.uc_color})\n",
        "\n",
        "        # =========== P-values + Benjamini-Hochberg correction\n",
        "        df_healthy = df.loc[df[\"Dataset\"] == \"Healthy\", [\"Sign\", \"Index\", \"Count\"]]\n",
        "        df_uc = df.loc[df[\"Dataset\"] == \"UC\", [\"Sign\", \"Index\", \"Count\"]]\n",
        "        df_merged = df_healthy.merge(\n",
        "            df_uc,\n",
        "            left_on=[\"Sign\", \"Index\"],\n",
        "            right_on=[\"Sign\", \"Index\"],\n",
        "            how=\"inner\",\n",
        "            suffixes=[\"Healthy\", \"UC\"]\n",
        "        )\n",
        "\n",
        "        # Compute statistic (raw p-values)\n",
        "        def fn(tbl):\n",
        "            u = scipy.stats.mannwhitneyu(\n",
        "                tbl[\"CountHealthy\"], tbl[\"CountUC\"],\n",
        "                alternative=\"less\"\n",
        "            )\n",
        "            return u\n",
        "\n",
        "        pvalues = df_merged.groupby(\n",
        "            \"Sign\"\n",
        "        ).apply(fn)\n",
        "\n",
        "        pvalues_df = pd.DataFrame(\n",
        "            {\"pvalue\": pvalues.sort_values()}\n",
        "        )\n",
        "\n",
        "        # Apply BH correction\n",
        "        p_adjusted = []\n",
        "        p_adj_prev = 0.0\n",
        "        for i, (index, row) in enumerate(pvalues_df.iterrows()):\n",
        "            p_adj = row[\"pvalue\"].pvalue * pvalues_df.shape[0] / (i+1)\n",
        "            p_adj = min(max(p_adj, p_adj_prev), 1)\n",
        "            p_adjusted.append(p_adj)\n",
        "            p_adj_prev = p_adj\n",
        "\n",
        "        pvalues_df[\"pvalue_adj\"] = p_adjusted\n",
        "\n",
        "\n",
        "\n",
        "        pvalues_df = pvalues_df.reset_index()\n",
        "        sig_signs = pvalues_df.loc[pvalues_df[\"pvalue_adj\"] <= 1e-3, \"Sign\"]\n",
        "        display(pvalues_df)\n",
        "\n",
        "        for sgn in sig_signs:\n",
        "            idx = sign_order[sgn]\n",
        "            pval = pvalues_df.loc[pvalues_df['Sign'] == sgn, 'pvalue_adj'].item()\n",
        "            if pval <= 1e-4:\n",
        "                indicator = \"****\"\n",
        "            elif pval <= 1e-3:\n",
        "                indicator = \"***\"\n",
        "            else:\n",
        "                indicator = \"ERR\"\n",
        "            y = df.loc[df['Sign'] == sgn, \"Count\"].max()\n",
        "            stat_annotate(idx-0.5, idx+0.5, y=y, h=0.5, ax=ax, color='black', desc=indicator)\n",
        "        ax.set_ylabel(\"Number of cycles per sample\")\n",
        "\n",
        "\n",
        "# Preprocessing for Cycles (Figure F)\n",
        "class MdsineOutput(object):\n",
        "    '''\n",
        "    A class to encode the data output by MDSINE.\n",
        "    '''\n",
        "    def __init__(self, dataset_name, pkl_path):\n",
        "        self.dataset_name = dataset_name\n",
        "        self.mcmc = md2.BaseMCMC.load(pkl_path)\n",
        "        self.taxa = self.mcmc.graph.data.taxa\n",
        "        self.name_to_taxa = {otu.name: otu for otu in self.taxa}\n",
        "\n",
        "        self.interactions = None\n",
        "        self.clustering = None\n",
        "\n",
        "        self.clusters_by_idx = {\n",
        "            (c_idx): [self.get_taxa(oidx) for oidx in cluster.members]\n",
        "            for c_idx, cluster in enumerate(self.get_clustering())\n",
        "        }\n",
        "\n",
        "    @property\n",
        "    def num_samples(self) -> int:\n",
        "        return self.mcmc.n_samples\n",
        "\n",
        "    def get_cluster_df(self):\n",
        "        return pd.DataFrame([\n",
        "            {\n",
        "                \"id\": cluster.id,\n",
        "                \"idx\": c_idx+1,\n",
        "                \"otus\": \",\".join([self.get_taxa(otu_idx).name for otu_idx in cluster.members]),\n",
        "                \"size\": len(cluster)\n",
        "            }\n",
        "            for c_idx, cluster in enumerate(self.clustering)\n",
        "        ])\n",
        "\n",
        "    def get_interactions(self):\n",
        "        if self.interactions is None:\n",
        "            self.interactions = self.mcmc.graph[STRNAMES.INTERACTIONS_OBJ].get_trace_from_disk(section='posterior')\n",
        "        return self.interactions\n",
        "\n",
        "    def get_taxa(self, idx):\n",
        "        return self.taxa.index[idx]\n",
        "\n",
        "    def get_taxa_by_name(self, name: str):\n",
        "        return self.name_to_taxa[name]\n",
        "\n",
        "    def get_taxa_str(self, idx):\n",
        "        tax = self.taxa.index[idx].taxonomy\n",
        "        family = tax[\"family\"]\n",
        "        genus = tax[\"genus\"]\n",
        "        species = tax[\"species\"]\n",
        "\n",
        "        if genus == \"NA\":\n",
        "            return \"{}**\".format(family)\n",
        "        elif species == \"NA\":\n",
        "            return \"{}, {}*\".format(family, genus)\n",
        "        else:\n",
        "            return \"{}, {} {}\".format(family, genus, species)\n",
        "\n",
        "    def get_taxa_str_long(self, idx):\n",
        "        return \"{}\\n[{}]\".format(self.get_taxa(idx).name, self.get_taxa_str(idx))\n",
        "\n",
        "    def get_clustering(self):\n",
        "        if self.clustering is None:\n",
        "            self.clustering = self.mcmc.graph[STRNAMES.CLUSTERING_OBJ]\n",
        "            for cidx, cluster in enumerate(self.clustering):\n",
        "                cluster.idx = cidx\n",
        "        return self.clustering\n",
        "\n",
        "    def get_clustered_interactions(self):\n",
        "        clusters = self.get_clustering()\n",
        "        otu_interactions = self.get_interactions()\n",
        "        cluster_interactions = np.zeros(\n",
        "            shape=(\n",
        "                otu_interactions.shape[0],\n",
        "                len(clusters),\n",
        "                len(clusters)\n",
        "            ),\n",
        "            dtype=np.float\n",
        "        )\n",
        "        cluster_reps = [\n",
        "            next(iter(cluster.members)) for cluster in clusters\n",
        "        ]\n",
        "        for i in range(cluster_interactions.shape[0]):\n",
        "            cluster_interactions[i] = otu_interactions[i][np.ix_(cluster_reps, cluster_reps)]\n",
        "        return cluster_interactions\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "id": "ldiCAE--K62T"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Figure 6A + 6B\n",
        "\n",
        "A: Deviation from unperturbed steady state for random perturbations on a random α-fraction of taxa.\n",
        "\n",
        "B: Change in α-diversity for the same set of simulated trajectories."
      ],
      "metadata": {
        "id": "olhlf_zyVBdJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pert_path = \"/content/fwsim_random_pert\"\n",
        "pert_fig = PerturbationSimFigure(Path(\n",
        "    pert_path  # Used to be /data/cctm/darpa_perturbation_mouse_study/youn_notebooks/fwsim_random_pert\n",
        "))\n",
        "\n",
        "fig, axes = plt.subplots(2, 1, figsize=(15,20))\n",
        "\n",
        "pert_fig.plot_deviations(axes[0], ymin=0.0, ymax=1.5)\n",
        "pert_fig.plot_diversity(axes[1])\n",
        "fig.savefig(\"{}/figure6ab.pdf\".format(saveloc))"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "id": "VUaioJsICV4k"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Figure 6C\n",
        "\n",
        "Histogram of real, positive parts of eigenvalues."
      ],
      "metadata": {
        "id": "OVs4U6RiVj2y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "mcmc_healthy_path_unfixed = \"/content/mixed_prior_unfixed/healthy-seed0-mixed/mcmc.pkl\"\n",
        "mcmc_uc_path_unfixed = \"/content/mixed_prior_unfixed/uc-seed0-mixed/mcmc.pkl\"\n",
        "eig_fig = EigenvalueFigure(mcmc_healthy_path_unfixed, mcmc_uc_path_unfixed)\n",
        "\n",
        "fig, ax = plt.subplots(1, 1, figsize=(15, 10))\n",
        "eig_fig.plot(ax)\n",
        "fig.savefig(\"{}/figure6c.pdf\".format(saveloc))"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "id": "Zzqi9WJaVrtF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Figure 6D\n",
        "\n",
        "Counting of module-level simple cycles."
      ],
      "metadata": {
        "id": "icclR8JrVuYA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "mcmc_healthy_path_fixed = \"/content/mixed_prior_fixed/healthy-seed0-mixed/mcmc.pkl\"\n",
        "mcmc_uc_path_fixed = \"/content/mixed_prior_fixed/uc-seed0-mixed/mcmc.pkl\"\n",
        "cycle_fig = CycleFigure(\n",
        "    mcmc_healthy_path_fixed, # Fixed clustering run\n",
        "    mcmc_uc_path_fixed  # Fixed clustering run\n",
        ")\n",
        "\n",
        "fig, ax = plt.subplots(1, 1, figsize=(15, 10))\n",
        "cycle_fig.plot(ax)\n",
        "fig.savefig(\"{}/figure6d.pdf\".format(saveloc))"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "id": "ds3Zix9LYiNC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Figure 7"
      ],
      "metadata": {
        "id": "MKtAdBbteCIv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Custom code necessary for rendering Keystoneness figure.\n",
        "\n"
      ],
      "metadata": {
        "id": "UpN4SrLOeEQ6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title\n",
        "import numpy as np\n",
        "import mdsine2 as md2\n",
        "from tqdm.notebook import tqdm\n",
        "import pandas as pd\n",
        "\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib import cm, gridspec\n",
        "import matplotlib.colors as mcolors\n",
        "import seaborn as sns\n",
        "\n",
        "\n",
        "def cluster_nonmembership_df(md):\n",
        "    entries = []\n",
        "    for cluster in md.get_clustering():\n",
        "        for otu in md.taxa:\n",
        "            if otu.idx not in cluster.members:\n",
        "                entries.append({\n",
        "                    \"ClusterID\": cluster.id,\n",
        "                    \"OTU\": otu.name\n",
        "                })\n",
        "    return pd.DataFrame(entries)\n",
        "\n",
        "\n",
        "def cluster_membership_df(md):\n",
        "    entries = []\n",
        "    for cluster in md.get_clustering():\n",
        "        for oidx in cluster.members:\n",
        "            otu = md.get_taxa(oidx)\n",
        "            entries.append({\n",
        "                \"ClusterOfOTU\": cluster.id,\n",
        "                \"OTU\": otu.name\n",
        "            })\n",
        "    return pd.DataFrame(entries)\n",
        "\n",
        "\n",
        "def create_cmap(tag, nan_value=\"red\"):\n",
        "    cmap = cm.get_cmap(tag)\n",
        "    cmap.set_bad(color=nan_value)\n",
        "    return cmap\n",
        "\n",
        "\n",
        "class KeystonenessFigure():\n",
        "    def __init__(self, dataset_name: str, mcmc_pickle_path, subjset_path, fwsim_path):\n",
        "        print(\"Loading pickle files.\")\n",
        "        self.md = MdsineOutput(dataset_name, mcmc_pickle_path)\n",
        "        self.study = md2.Study.load(subjset_path)\n",
        "        \n",
        "        print(\"Loading dataframe from disk.\")\n",
        "        self.fwsim_df = pd.read_hdf(fwsim_path, key='df', mode='r')\n",
        "        \n",
        "        print(\"Compiling dataframe.\")\n",
        "        self.ky_df = self.generate_keystoneness_df()\n",
        "        \n",
        "        print(\"Compiling abundance data.\")\n",
        "        self.abundance_array = self.get_abundance_array()\n",
        "        \n",
        "        print(\"Extracting keystoneness values.\")\n",
        "        self.ky_array = self.get_ky_array()\n",
        "        \n",
        "        print(\"Extracting baseline abundances.\")\n",
        "        self.day20_array = self.get_day20_abundances()\n",
        "\n",
        "    def generate_keystoneness_df(self):\n",
        "        md = self.md\n",
        "        fwsim_df = self.fwsim_df\n",
        "        \n",
        "        nonmembers_df = cluster_nonmembership_df(md)\n",
        "\n",
        "        baseline = fwsim_df.loc[fwsim_df[\"ExcludedCluster\"] == \"None\"]\n",
        "\n",
        "        altered = fwsim_df.loc[fwsim_df[\"ExcludedCluster\"] != \"None\"]\n",
        "        altered = altered.merge(\n",
        "            right=nonmembers_df,\n",
        "            how=\"inner\",\n",
        "            left_on=[\"ExcludedCluster\", \"OTU\"],\n",
        "            right_on=[\"ClusterID\", \"OTU\"]\n",
        "        )\n",
        "\n",
        "        merged = altered.merge(\n",
        "            baseline[[\"OTU\", \"SampleIdx\", \"StableState\"]],\n",
        "            how=\"left\",\n",
        "            left_on=[\"OTU\", \"SampleIdx\"],\n",
        "            right_on=[\"OTU\", \"SampleIdx\"],\n",
        "            suffixes=[\"\", \"Base\"] \n",
        "        )\n",
        "        \n",
        "        merged[\"DiffStableState\"] = np.log10(merged[\"StableStateBase\"] + 1e5) - np.log10(merged[\"StableState\"] + 1e5)\n",
        "\n",
        "        return merged[\n",
        "            [\"ExcludedCluster\", \"SampleIdx\", \"DiffStableState\"]\n",
        "        ].groupby(\n",
        "            [\"ExcludedCluster\", \"SampleIdx\"]\n",
        "        ).mean().rename(columns={\"DiffStableState\": \"Ky\"})\n",
        "    \n",
        "    def get_abundance_array(self):\n",
        "        md = self.md\n",
        "        fwsim_df = self.fwsim_df\n",
        "        \n",
        "        clustering = md.get_clustering()\n",
        "        membership_df = cluster_membership_df(md)\n",
        "        merged_df = fwsim_df.merge(\n",
        "            membership_df,\n",
        "            how=\"left\",\n",
        "            left_on=\"OTU\",\n",
        "            right_on=\"OTU\"\n",
        "        )\n",
        "        \n",
        "        abund_array = np.zeros(shape=(len(clustering) + 1, len(clustering)))\n",
        "\n",
        "        # Baseline abundances (no cluster removed) -- sum across OTUs (per sample), median across samples.\n",
        "        subset_df = merged_df.loc[merged_df[\"ExcludedCluster\"] == \"None\"]\n",
        "        subset_df = subset_df[\n",
        "            [\"ClusterOfOTU\", \"SampleIdx\", \"StableState\"]\n",
        "        ].groupby(\n",
        "            [\"ClusterOfOTU\", \"SampleIdx\"]\n",
        "        ).sum(\n",
        "            # Aggregate over OTUs  (e.g. Baseline abundance of a cluster is the sum of its constituents.)\n",
        "        ).groupby(\n",
        "            level=0\n",
        "        ).median(\n",
        "            # Aggregate over samples\n",
        "        )\n",
        "        for cluster in clustering:\n",
        "            abund_array[0, cluster.idx] = subset_df.loc[cluster.id]\n",
        "\n",
        "        # Altered abundances (remove 1 cluster at a time)\n",
        "        for removed_cluster in tqdm(clustering, total=len(clustering), desc=\"Heatmap Abundances\"):\n",
        "            subset_df = merged_df.loc[merged_df[\"ExcludedCluster\"] == removed_cluster.id]\n",
        "\n",
        "            # Compute the total abundance (over OTUs) for each cluster, for each sample. Then aggregate (median) across samples.\n",
        "            subset_df = subset_df[\n",
        "                [\"ClusterOfOTU\", \"SampleIdx\", \"StableState\"]\n",
        "            ].groupby(\n",
        "                [\"ClusterOfOTU\", \"SampleIdx\"]\n",
        "            ).sum(\n",
        "                # Aggregate over OTUs\n",
        "            ).groupby(\n",
        "                level=0\n",
        "            ).median(\n",
        "                # Aggregate over samples\n",
        "            )\n",
        "\n",
        "            for cluster in clustering:\n",
        "                abund_array[removed_cluster.idx + 1, cluster.idx] = subset_df.loc[cluster.id]\n",
        "        return abund_array\n",
        "    \n",
        "    def get_ky_array(self):\n",
        "        # Group by Cluster, aggregate (mean/median) across samples.\n",
        "        agg_ky_df = self.ky_df.groupby(level=0).median()\n",
        "        return np.array(\n",
        "            [agg_ky_df.loc[cluster.id, \"Ky\"] for cluster in self.md.get_clustering()]\n",
        "        )\n",
        "    \n",
        "    def get_day20_abundances(self):\n",
        "        M = self.study.matrix(dtype='abs', agg='mean', times='intersection', qpcr_unnormalize=True)\n",
        "        day20_state = M[:, 19]\n",
        "        cluster_day20_abundances = np.zeros(len(self.md.get_clustering()))\n",
        "\n",
        "        for cidx, cluster in enumerate(self.md.get_clustering()):\n",
        "            cluster_day20_abundances[cidx] = np.sum(\n",
        "                [day20_state[oidx] for oidx in cluster.members]\n",
        "            )\n",
        "        return cluster_day20_abundances\n",
        "    \n",
        "    def plot(self, fig):\n",
        "        md = self.md\n",
        "        abund_array = self.abundance_array\n",
        "        ky_array = self.ky_array\n",
        "        day20_array = self.day20_array\n",
        "        \n",
        "        # Main abundance grid shows the _difference_ from baseline, instead of the abundances itself.\n",
        "        n_clusters = len(ky_array)\n",
        "\n",
        "        # =========== Pre-sorting. ===========\n",
        "        ky_order = np.argsort(ky_array)\n",
        "        ky_order = ky_order[::-1]\n",
        "        ky_array = ky_array[ky_order]\n",
        "\n",
        "        day20_array = day20_array[ky_order].reshape(1, len(day20_array))\n",
        "\n",
        "        baseline_array = abund_array[[0], :]\n",
        "        baseline_array = baseline_array[:, ky_order]\n",
        "\n",
        "        altered_array = abund_array[1 + ky_order, :]  # Reorder the rows first (exclude the baseline row),\n",
        "        altered_array = altered_array[:, ky_order]  # Then reorder the columns.\n",
        "\n",
        "        baseline_diff_array = np.log10(baseline_array + 1e5) - np.log10(altered_array + 1e5)\n",
        "        for i in range(baseline_diff_array.shape[0]):\n",
        "            baseline_diff_array[i, i] = np.nan\n",
        "\n",
        "        # =========== Heatmap settings. ========\n",
        "        gridspec_kw = {\"height_ratios\":[1, 1, abund_array.shape[0] - 1], \"width_ratios\" : [1, abund_array.shape[1]]}\n",
        "\n",
        "        # Colors and normalization (abund)\n",
        "        abund_min = np.max([\n",
        "            np.min(abund_array[abund_array > 0]), \n",
        "            1e5\n",
        "        ])\n",
        "        abund_max = np.min([\n",
        "            np.max(abund_array[abund_array > 0]),\n",
        "            1e13\n",
        "        ])\n",
        "        print(\"abund_min = {}, abund_max = {}\".format(abund_min, abund_max))\n",
        "\n",
        "        abund_cmap = create_cmap(\"Greens\", nan_value=\"white\")\n",
        "        abund_norm = matplotlib.colors.LogNorm(vmin=abund_min, vmax=abund_max)\n",
        "\n",
        "        # Colors and normalization (Ky)\n",
        "        gray = np.array([0.95, 0.95, 0.95, 1.0])\n",
        "        red = np.array([1.0, 0.0, 0.0, 1.0])\n",
        "        blue = np.array([0.0, 0.0, 1.0, 1.0])\n",
        "        n_interp=128\n",
        "\n",
        "        top = blue\n",
        "        bottom = red\n",
        "        top_middle = 0.05 * top + 0.95 * gray\n",
        "        bottom_middle = 0.05 * bottom + 0.95 * gray\n",
        "\n",
        "        ky_cmap = matplotlib.colors.ListedColormap(\n",
        "            np.vstack(\n",
        "                [(1-t) * bottom + t * bottom_middle for t in np.linspace(0, 1, n_interp)]\n",
        "                +\n",
        "                [(1-t) * top_middle + t * top for t in np.linspace(0, 1, n_interp)]\n",
        "            ),\n",
        "            name='Keystoneness'\n",
        "        )\n",
        "        ky_cmap.set_bad(color=\"white\")\n",
        "\n",
        "\n",
        "        ky_min = 0.90 * np.min(ky_array) + 0.10 * np.min(baseline_diff_array[altered_array > 0])\n",
        "        ky_max = 0.90 * np.max(ky_array) + 0.10 * np.max(baseline_diff_array[altered_array > 0])\n",
        "\n",
        "        ky_norm = matplotlib.colors.TwoSlopeNorm(vmin=ky_min, vcenter=0, vmax=ky_max)\n",
        "        def _forward(x):\n",
        "            y = x.copy()\n",
        "            positive_part = x[x > 0]\n",
        "            y[x > 0] = np.sqrt(positive_part / ky_max)\n",
        "\n",
        "            negative_part = x[x < 0]\n",
        "            y[x < 0] = -np.sqrt(np.abs(negative_part / ky_min))\n",
        "            return y\n",
        "        def _reverse(x):\n",
        "            y = x.copy()\n",
        "            positive_part = x[x > 0]\n",
        "            y[x > 0] = ky_max * np.power(positive_part, 2)\n",
        "\n",
        "            negative_part = x[x < 0]\n",
        "            y[x < 0] = -np.abs(ky_min) * np.power(negative_part, 2)\n",
        "            return y\n",
        "        ky_norm = matplotlib.colors.FuncNorm((_forward, _reverse), vmin=ky_min, vmax=ky_max)\n",
        "\n",
        "        # Seaborn Heatmap Kwargs\n",
        "        abund_heatmapkws = dict(square=False, \n",
        "                                cbar=False, \n",
        "                                cmap=abund_cmap, \n",
        "                                linewidths=0.5,\n",
        "                                norm=abund_norm)\n",
        "        ky_heatmapkws = dict(square=False, cbar=False, cmap=ky_cmap, linewidths=0.5, norm=ky_norm)\n",
        "\n",
        "        # ========== Plot layout ===========\n",
        "    #     [left, bottom, width, height]\n",
        "        main_x = 0.67\n",
        "        main_y = 0.5\n",
        "        box_unit = 0.03\n",
        "        main_width = box_unit * n_clusters\n",
        "        main_height = main_width\n",
        "        main_left = main_x - 0.5 * main_width\n",
        "        main_bottom = main_y - 0.5 * main_width\n",
        "        print(\"Left: {}, bottom: {}, width: {}, height: {}\".format(main_left, main_bottom, main_width, main_height))\n",
        "        print(\"Right: {}, Top: {}\".format(main_left + main_width, main_bottom + main_height))\n",
        "\n",
        "        ky_ax = fig.add_axes([main_left + main_width + 0.5 * box_unit, main_bottom, box_unit, main_height])\n",
        "        abundances_ax = fig.add_axes([main_left, main_bottom, main_width, main_height])\n",
        "        obs_ax = fig.add_axes([main_left, main_bottom + main_height + 1.5 * box_unit, box_unit * n_clusters, box_unit])\n",
        "        baseline_ax = fig.add_axes([main_left, main_bottom + main_height + 0.5 * box_unit, box_unit * n_clusters, box_unit])\n",
        "\n",
        "        # ========= Rendering. ==========\n",
        "        # ====== Bottom left: Keystoneness\n",
        "        hmap_ky = sns.heatmap(\n",
        "            ky_array.reshape(len(ky_array), 1),\n",
        "            ax=ky_ax,\n",
        "            xticklabels=False,\n",
        "            yticklabels=False,\n",
        "            **ky_heatmapkws\n",
        "        )\n",
        "        hmap_ky.xaxis.set_tick_params(width=0)\n",
        "        fig.text(main_left + main_width + 2*box_unit, main_y, \"Keystoneness\", ha='center', va='center', rotation=-90)\n",
        "\n",
        "        for _, spine in hmap_ky.spines.items():\n",
        "            spine.set_visible(True)\n",
        "            spine.set_linewidth(1.0)\n",
        "\n",
        "        # ====== Top right 1: Observed levels (day 20)\n",
        "        hmap_day20_abund = sns.heatmap(day20_array, \n",
        "                                       ax=obs_ax, \n",
        "                                       xticklabels=False, \n",
        "                                       yticklabels=[\"Observation\"],\n",
        "                                       **abund_heatmapkws)\n",
        "        hmap_day20_abund.set_yticklabels(hmap_day20_abund.get_yticklabels(), rotation=0)\n",
        "        for _, spine in hmap_day20_abund.spines.items():\n",
        "            spine.set_visible(True)\n",
        "            spine.set_linewidth(1.0)\n",
        "        fig.text(main_x, main_bottom + main_height + 3 * box_unit, \"Steady State Abundance\", ha='center', va='center')\n",
        "\n",
        "        # ====== Top right 2: Baseline abundances\n",
        "        hmap_base_abund = sns.heatmap(baseline_array, \n",
        "                                      ax=baseline_ax, \n",
        "                                      xticklabels=False, \n",
        "                                      yticklabels=[\"Simulation\"],\n",
        "                                      **abund_heatmapkws)\n",
        "        hmap_base_abund.set_yticklabels(hmap_base_abund.get_yticklabels(), rotation=0)\n",
        "        for _, spine in hmap_base_abund.spines.items():\n",
        "            spine.set_visible(True)\n",
        "            spine.set_linewidth(1.0)\n",
        "\n",
        "        # ====== Bottom right: Abundances with clusters removed.\n",
        "        ticklabels = [\n",
        "            \"{}{}\".format(\n",
        "                \"H\" if md.dataset_name == \"Healthy\" else \"D\", \n",
        "                c_idx + 1\n",
        "            ) \n",
        "            for c_idx in ky_order\n",
        "        ]\n",
        "        hmap_removed_cluster_abund = sns.heatmap(\n",
        "            baseline_diff_array, \n",
        "            ax=abundances_ax, \n",
        "            xticklabels=ticklabels, \n",
        "            yticklabels=ticklabels, \n",
        "            **ky_heatmapkws\n",
        "        )\n",
        "        # Draw a marker (\"X\") on top of NaNs.\n",
        "        abundances_ax.scatter(*np.argwhere(np.isnan(baseline_diff_array.T)).T + 0.5, marker=\"x\", color=\"black\", s=100)\n",
        "        abundances_ax.set_ylabel(\"Module Removed\")\n",
        "        abundances_ax.set_xlabel(\"Per-Module Change\")\n",
        "        for _, spine in hmap_removed_cluster_abund.spines.items():\n",
        "            spine.set_visible(True)\n",
        "            spine.set_linewidth(1.0)\n",
        "        hmap_removed_cluster_abund.xaxis.set_ticks_position('bottom')\n",
        "        hmap_removed_cluster_abund.set_xticklabels(\n",
        "            hmap_removed_cluster_abund.get_xticklabels(), rotation=90, horizontalalignment='center'\n",
        "        )\n",
        "        abundances_ax.tick_params(direction='out', length=0, width=0)\n",
        "\n",
        "        # ======= Draw the colormaps ========\n",
        "        cbar_from_main = 0.25\n",
        "        cbar_width = 0.01\n",
        "        cbar_height = 0.35\n",
        "\n",
        "        # Cbar on the right (steady state diff, green)\n",
        "        cax = fig.add_axes([main_left - cbar_from_main, main_y - 0.5 * cbar_height, cbar_width, cbar_height])\n",
        "        sm = matplotlib.cm.ScalarMappable(cmap=abund_cmap, norm=abund_norm)\n",
        "        sm.set_array(np.array([]))\n",
        "        cbar = fig.colorbar(sm, cax=cax)\n",
        "\n",
        "        yticks = cbar.get_ticks()\n",
        "        yticklabels = [str(np.log10(y)) for y in yticks]\n",
        "        yticklabels[0] = \"<{}\".format(yticklabels[0])  \n",
        "        cax.set_yticklabels(yticklabels)\n",
        "        cax.set_ylabel(\"Log-Abundance\")\n",
        "\n",
        "        # Cbar on the left (Keyst., RdBu)\n",
        "        cax = fig.add_axes([main_left - cbar_from_main - 2*cbar_width, main_y - 0.5 * cbar_height, cbar_width, cbar_height])\n",
        "        sm = matplotlib.cm.ScalarMappable(cmap=ky_cmap, norm=ky_norm)\n",
        "        sm.set_array(np.array([]))\n",
        "        cbar = fig.colorbar(sm, cax=cax)\n",
        "        cax.yaxis.set_ticks_position('left')\n",
        "        cax.set_ylabel(\"Log-Difference from Base\")\n",
        "        cax.yaxis.set_label_position(\"left\")\n",
        "\n",
        "        yticks = cbar.get_ticks()\n",
        "        yticklabels = [\"{:.1f}\".format(y) for y in yticks]\n",
        "        cax.set_yticklabels(yticklabels)\n",
        "\n",
        "        # Legend label text\n",
        "        fig.text(\n",
        "            main_left - cbar_from_main - cbar_width,\n",
        "            main_y + 0.5 * cbar_height + 0.05,\n",
        "            \"Legend\",\n",
        "            ha='center', va='center',\n",
        "            fontweight='bold'\n",
        "        )"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "id": "wxBHhuJbeB7K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "id": "t8GBg5giz9h1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Healthy Keystoneness values"
      ],
      "metadata": {
        "id": "xIFaP6CCen6k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "healthy_subjset_path = \"/content/MDSINE2_Paper/analysis/output/gibson/preprocessed/gibson_healthy_agg_taxa_filtered.pkl\"\n",
        "healthy_keystone_path = \"/content/keystoneness/healthy_fwsim_day20.h5\"\n",
        "fig = plt.figure(figsize=(10,10))\n",
        "KeystonenessFigure(\n",
        "    \"Healthy\",\n",
        "    mcmc_healthy_path_fixed,  # Fixed clustering run\n",
        "    healthy_subjset_path,\n",
        "    healthy_keystone_path  # Used to be: darpa_perturbation_mouse_study/youn_notebooks/keystoneness/healthy_fwsim_day20.h5\n",
        ").plot(fig)\n",
        "fig.savefig(\"{}/figure7_healthy.pdf\".format(saveloc))"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "id": "j7TuybyVefOU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Dysbiosis Keystoneness values"
      ],
      "metadata": {
        "id": "UgsBChtjep_e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "uc_subjset_path = \"/content/MDSINE2_Paper/analysis/output/gibson/preprocessed/gibson_uc_agg_taxa_filtered.pkl\"\n",
        "uc_keystone_path = \"/content/keystoneness/uc_fwsim_day20.h5\"\n",
        "fig = plt.figure(figsize=(10,10))\n",
        "\n",
        "KeystonenessFigure(\n",
        "    \"Dysbiotic\",\n",
        "    mcmc_uc_path_fixed,  # Fixed clustering run\n",
        "    uc_subjset_path,\n",
        "    uc_keystone_path  # Used to be: darpa_perturbation_mouse_study/youn_notebooks/keystoneness/uc_fwsim_day20.h5\n",
        ").plot(fig)\n",
        "fig.savefig(\"{}/figure7_dysbiotic.pdf\".format(saveloc))"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "id": "FOZXI91_fGRC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Supplemental Figure 1\n"
      ],
      "metadata": {
        "id": "zGyt8uZ-Spes"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python gibson_inference/figures/supplemental_figure1.py \\\n",
        "    -file1 \"gibson_inference/figures/preprocessed_all/gibson_healthy_agg_taxa.pkl\" \\\n",
        "    -file2 \"gibson_inference/figures/preprocessed_all/gibson_uc_agg_taxa.pkl\" \\\n",
        "    -file3 \"gibson_inference/figures/preprocessed_all/gibson_inoculum_agg_taxa.pkl\"\\\n",
        "    -o_loc \"output/gibson/plots\""
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "id": "tWLbwNIb5zLr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Supplemental Figure 2\n",
        "\n",
        "The whole figure is created in multiple steps. In the first step we plot, the relative abundance at the phylum level. Then, we separately make the heatmaps showing the deseq results. The final figure is made by combining the sub-figures in Adobe illustrator. \n"
      ],
      "metadata": {
        "id": "a0O9nD1dSwi7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###First Step"
      ],
      "metadata": {
        "id": "kHGUxqU3SK0n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python gibson_inference/figures/supplemental_figure2.py \\\n",
        "    -file1 \"gibson_inference/figures/preprocessed_all/gibson_healthy_agg_taxa.pkl\" \\\n",
        "    -file2 \"gibson_inference/figures/preprocessed_all/gibson_uc_agg_taxa.pkl\" \\\n",
        "    -file3 \"gibson_inference/figures/preprocessed_all/gibson_inoculum_agg_taxa.pkl\" \\\n",
        "    -o_loc \"output/gibson/plots\""
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "id": "tn7hCKXw5zzl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Heatmap showing DeSeq results at steady state at phylum level\n",
        "\n",
        "The heatmaps are saved as mat_phylum_high_ss and mat_phylum_low_ss. "
      ],
      "metadata": {
        "id": "3qRXxhlE5WkJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python gibson_inference/figures/deseq_heatmap_ss.py \\\n",
        "    -loc \"gibson_inference/figures/supplemental_figure2_files\" \\\n",
        "    -abund \"high\" \\\n",
        "    -txt \"abundant_species_phylum\" \\\n",
        "    -taxo \"phylum\" \\\n",
        "    -o \"mat_phylum_high_ss\" \\\n",
        "    -o_loc \"output/gibson/plots\"\n",
        "\n",
        "\n",
        "!python gibson_inference/figures/deseq_heatmap_ss.py \\\n",
        "    -loc \"gibson_inference/figures/supplemental_figure2_files\" \\\n",
        "    -abund \"low\" \\\n",
        "    -txt \"abundant_species_phylum\" \\\n",
        "    -taxo \"phylum\" \\\n",
        "    -o \"mat_phylum_low_ss\" \\\n",
        "    -o_loc \"output/gibson/plots\"\n",
        "\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "id": "JsWMT4-85UcQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "####Heatmap showing DeSeq results for different perturbations at phylum level\n",
        "The heatmaps are saved as mat_phylum_high and mat_phylum_low. "
      ],
      "metadata": {
        "id": "UvhKI_JnSkqD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python gibson_inference/figures/deseq_heatmap_phylum.py \\\n",
        "    -loc \"gibson_inference/figures/supplemental_figure2_files\" \\\n",
        "    -abund \"high\" \\\n",
        "    -txt \"abundant_species_phylum\" \\\n",
        "    -taxo \"phylum\" \\\n",
        "    -o \"mat_phylum_high\" \\\n",
        "    -o_loc \"output/gibson/plots\"\n",
        "\n",
        "\n",
        "!python gibson_inference/figures/deseq_heatmap_phylum.py \\\n",
        "    -loc \"gibson_inference/figures/supplemental_figure2_files\" \\\n",
        "    -abund \"low\" \\\n",
        "    -txt \"abundant_species_phylum\" \\\n",
        "    -taxo \"phylum\" \\\n",
        "    -o \"mat_phylum_low\" \\\n",
        "    -o_loc \"output/gibson/plots\""
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "id": "_cwlBj12SQ4r"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Heatmap showing results of DeSeq analysis at Order level\n",
        "\n",
        "The heatmaps are saved as mat_order_high and mat_order_low. "
      ],
      "metadata": {
        "id": "pGG_Ji1ozHBQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python gibson_inference/figures/deseq_heatmap_order.py \\\n",
        "    -loc \"gibson_inference/figures/supplemental_figure2_files\" \\\n",
        "    -abund \"high\" \\\n",
        "    -txt \"abundant_species_order\" \\\n",
        "    -taxo \"order\" \\\n",
        "    -o \"mat_order_high\" \\\n",
        "    -o_loc \"output/gibson/plots\"\n",
        "\n",
        "\n",
        "!python gibson_inference/figures/deseq_heatmap_order.py \\\n",
        "    -loc \"gibson_inference/figures/supplemental_figure2_files\" \\\n",
        "    -abund \"low\" \\\n",
        "    -txt \"abundant_species_order\" \\\n",
        "    -taxo \"order\" \\\n",
        "    -o \"mat_order_low\" \\\n",
        "    -o_loc \"output/gibson/plots\"\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "id": "eh5o_TgMy_B2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Supplemental Figure 3"
      ],
      "metadata": {
        "id": "PHoBDyXqTVZK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python gibson_inference/figures/supplemental_figure3.py \\\n",
        "    -file1 \"output/gibson/preprocessed/gibson_healthy_agg_taxa.pkl\" \\\n",
        "    -file2 \"output/gibson/preprocessed/gibson_uc_agg_taxa.pkl\" \\\n",
        "    -o_loc \"output/gibson/plots\"\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "id": "Nv4GbGW-54lc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Supplemental Figure 4"
      ],
      "metadata": {
        "id": "69tvuYvvTpEK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python gibson_inference/figures/supplemental_figure4.py \\\n",
        "    --mdsine_path \"/content/forward_sims/\"\\\n",
        "    --clv_elas_path \"/content/clv_results/results_rel_elastic/\"\\\n",
        "    --clv_ridge_path \"/content/clv_results/results_rel_ridge/\"\\\n",
        "    --glv_elas_path \"/content/clv_results/results_abs_elastic/\"\\\n",
        "    --glv_ridge_path \"/content/clv_results/results_abs_ridge/forward_sims_abs_ridge/\"\\\n",
        "    --output_path \"output/gibson/plots/\""
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "id": "udkkmVXN585a"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Supplemental Figure 5"
      ],
      "metadata": {
        "id": "2tAifSyoTeDq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python gibson_inference/figures/supplemental_figure5.py \\\n",
        "     -loc1 \"/content/mixed_prior_fixed/healthy-seed0-mixed/mcmc.pkl\"\\\n",
        "     -loc2 \"/content/mixed_prior_fixed/uc-seed0-mixed/mcmc.pkl\"\\\n",
        "     -o_loc \"output/gibson/plots\"\n",
        "\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "id": "bPDBL27_6CS1"
      }
    }
  ],
  "metadata": {
    "colab": {
      "name": "colab_reproduce_figures",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "nteract": {
      "version": "0.28.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}